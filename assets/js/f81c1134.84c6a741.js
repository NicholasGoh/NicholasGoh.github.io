"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[8130],{7735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"customer-service-automation","metadata":{"permalink":"/blog/customer-service-automation","source":"@site/blog/2025-03-01-customer-service/index.mdx","title":"Customer Service Automation","description":"Introduction","date":"2025-03-01T00:00:00.000Z","tags":[{"inline":true,"label":"agentic-workflow","permalink":"/blog/tags/agentic-workflow"},{"inline":true,"label":"multi-agents","permalink":"/blog/tags/multi-agents"}],"readingTime":7.92,"hasTruncateMarker":true,"authors":[{"name":"Nicholas Goh","title":"AI Full Stack Engineer","url":"https://nicholas-goh.com","page":{"permalink":"/blog/authors/all-nicholas-goh-articles"},"socials":{"linkedin":"https://www.linkedin.com/in/nicholas-goh-19ba1b194/","github":"https://github.com/NicholasGoh"},"imageURL":"https://avatars.githubusercontent.com/u/58037050?s=400&u=cc1cb1686de3cfbf92b95cd8b8bad22291c1a068&v=4","key":"nicholas"}],"frontMatter":{"slug":"customer-service-automation","title":"Customer Service Automation","authors":["nicholas"],"tags":["agentic-workflow","multi-agents"]},"unlisted":false,"nextItem":{"title":"ETL Automation","permalink":"/blog/etl-automation"}},"content":"import ReactPlayer from \'react-player\'\\n\\n## Introduction\\n\\nIn this blog, I explore how a complex problem with moving parts can be solved, by having it broken down into smaller problems to be solved\u2014automatically.\\n\\n\x3c!-- truncate --\x3e\\n\\n## AI\u2019s Impact: Aligning Tech with Strategy\\n\\nFollowing from previous blog, suppose the (manual, semi automatic or automatic) ingestion of data from multiple service providers is done. How can a system answer users\' queries? First lets group some possible queries into categories.\\n\\n| Query | Category |\\n|-------------------------------|------------------|\\n| Do you clean kitchen and cabinets? | Service |\\n| How much do you charge for cleaning toilets? | Service |\\n| Is Jan 20 available for booking at 9am? | Booking |\\n\\nOf course, any combination of the above queries and alike can be asked by the customer, which brings about some questions:\\n\\n- How do we decide which category a question belongs to?\\n- What if a question has multiple parts\u2014how do we process them in the right order?\\n- Once we understand the question, how do we fetch and return the right information?\\n\\nFor example, if a user asks: \\"How much do you charge for cleaning toilets? Is Jan 20 available for booking at 9am?\\", the system needs to:\\n1. Recognize this is actually two separate queries\u2014one about pricing and one about booking.\\n2. Process them in a way that makes sense (e.g., retrieve price then check availability).\\n\\nNotice that queries thus far are phrase in perfect English\u2014this is rarely how users phrase them. In reality, queries might be more fragmented or ambiguous. For example, someone might ask: \\"toilet how much and jan 20 9am can\\". See [demo](#demo) for more examples. I modeled how this could be done in reality.\\n\\n## The Importance of Orchestration\\n\\n### Supervisor\\n\\nSimilar to real life, a Supervisor would:\\n\\n- break down complex tasks into smaller tasks for specialized assistants\\n- rewrite ambiguous queries into clearer requests (e.g., \\"toilet how much and jan 20 9am can\\" becomes \\"What is the price for cleaning a toilet?\\" and \\"Is Jan 20 available for booking at 9am?\\")\\n\\n```mermaid\\ngraph TD\\n    A[Query] --\x3e B[Supervisor]\\n\\n    B -.-> |Translate| C[Service Assistant]\\n    C --\x3e |Interpret| B\\n\\n    B -.->|Translate| D[Booking Assistant]\\n    D --\x3e|Interpret| B\\n\\n    B -.-> E[Finish]\\n\\nsubgraph Legend\\n    L1(( )) -.->|Optional| L2(( ))\\n    L3(( )) --\x3e|Mandatory| L4(( ))\\nend\\n```\\n\\n### Service Assistant\\n\\nHaving access to the possible cleaning services provided and the respective costs, the Service Assistant would:\\n\\n- Reference the diagram to answer service related questions\\n\\n```mermaid\\ngraph TD\\n    A[Translation] --\x3e B[Service Assistant]\\n\\n    B -.-> |Translate| C[Service Diagram]\\n    C --\x3e B\\n\\n    B -.->|Interpret| D[Supervisor]\\n\\nsubgraph Legend\\n    L1(( )) -.->|Optional| L2(( ))\\n    L3(( )) --\x3e|Mandatory| L4(( ))\\nend\\n```\\n\\n\\n:::warning[Huge Diagram]\\n\\n<details>\\n\\n  <summary>Service Diagram</summary>\\n\\n```mermaid\\nflowchart LR\\n    A[Living Area & Bedroom Cleaning] --\x3e B[Tasks]\\n    B --\x3e|Dusting| C[Dust from top to bottom - $20]\\n    B --\x3e|Dusting| D[Dust light fixtures and fans - $15]\\n    B --\x3e|Dusting| E[Dust baseboards - $10]\\n    B --\x3e|Blinds & Window Sills| F[Wipe blinds and window sills - $15]\\n    B --\x3e|Vacuuming| G[Vacuum all floors - $25]\\n    B --\x3e|Mopping| H[Mop hard surface flooring - $20]\\n    B --\x3e|Trash| I[Empty trash bins - $10]\\n    B --\x3e|Mirrors| J[Clean all mirrors - $15]\\n    B --\x3e|Furniture| K[Clean furniture and decorative pieces - $30]\\n    B --\x3e|Smudges| L[Remove all fingerprints and smudges - $10]\\n    B --\x3e|Beds| M[Make beds - $20]\\n    B --\x3e|Electronics| N[Dust electronics, lamps and lampshades - $20]\\n    B --\x3e|Sanitize| O[Sanitize all remote controls and gaming equipment - $15]\\n    B --\x3e|Tidy| P[Tidy electronic cables - $10]\\n    B --\x3e|Tidy| Q[Tidy dressers - $15]\\n    B --\x3e|Sanitize| R[Wipe and sanitise door knobs - $5]\\n    B --\x3e|Sanitize| S[Wipe and sanitise light switches - $5]\\n    B --\x3e|Recycling| T[Place recyclable items aside for public Recycling Bin - $5]\\n\\n    A --\x3e U[Kitchen Cleaning]\\n    U --\x3e V[Tasks]\\n    V --\x3e|Dusting| W[Dust from top to bottom - $20]\\n    V --\x3e|Cleaning| X[Clean light fixtures and fans - $15]\\n    V --\x3e|Sink & Countertop| Y[Clean sinks and counters - $25]\\n    V --\x3e|Faucets & Drains| Z[Clean faucets and drains, remove any debris that could clog the drain - $20]\\n    V --\x3e|Backsplash| AA[Wipe backsplash, remove grease and grime - $20]\\n    V --\x3e|Cabinets| AB[Wipe all cabinets exterior - $15]\\n    V --\x3e|Vacuum & Mop| AC[Vacuum and mop floors - $25]\\n    V --\x3e|Stovetop & Hood| AD[Wipe stovetop and hood - $15]\\n    V --\x3e|Appliance Cleaning| AE[Clean appliances exterior - $20]\\n    V --\x3e|Fridge Cleaning| AF[Clean fridge exterior - $20]\\n    V --\x3e|Trash| AG[Empty trash bins - $10]\\n    V --\x3e|Recycling| AH[Place recyclable items aside for public Recycling Bin - $5]\\n    V --\x3e|Blinds & Sills| AI[Wipe blinds and window sills - $15]\\n    V --\x3e|Sanitize| AJ[Wipe and sanitise door knobs - $5]\\n    V --\x3e|Sanitize| AK[Wipe and sanitise light switches - $5]\\n\\n    A --\x3e BATHROOM\\n    BATHROOM --\x3e C[Tasks]\\n    C --\x3e|Dusting| AL[Dust from top to bottom - $20]\\n    C --\x3e|Light Fixtures| AM[Wipe light fixtures - $15]\\n    C --\x3e|Blinds & Sills| AN[Wipe blinds and window sills - $15]\\n    C --\x3e|Sink & Countertop| AO[Clean sink and countertops - $25]\\n    C --\x3e|Mirrors| AP[Clean mirrors - $15]\\n    C --\x3e|Faucets & Drains| AQ[Clean faucets and drains, remove any debris that could clog the drain - $20]\\n    C --\x3e|Toilet| AR[Scrub toilet - $30]\\n    C --\x3e|Floors| AS[Mop floors, scrub tiles if needed - $25]\\n    C --\x3e|Shower| AT[Clean shower stall - $40]\\n    C --\x3e|Bathtub| AU[Clean bathtub - $35]\\n    C --\x3e|Shower Racks| AV[Wash shower racks - $10]\\n    C --\x3e|Towels| AW[Fold and hang towels - $10]\\n    C --\x3e|Fragrance| AX[Freshen toilets with fragrance - $5]\\n    C --\x3e|Trash| AY[Empty trash bins - $10]\\n    C --\x3e|Sanitize| AZ[Wipe and sanitise door knobs - $5]\\n    C --\x3e|Sanitize| BA[Wipe and sanitise light switches - $5]\\n    C --\x3e|Recycling| BB[Place recyclable items aside for public Recycling Bin - $5]\\n```\\n\\n</details>\\n\\n:::\\n\\n### Booking Assistant\\n\\nHaving access to the booking system, the Booking Assistant would:\\n\\n- Check if the requested time slot is available.\\n- Confirm whether the user wants to proceed with the booking if the slot is open.\\n- Notify the user if the slot is unavailable and suggest the next available time.\\n\\n```mermaid\\ngraph TD\\n    A[Translation] --\x3e B[Booking Assistant]\\n\\n    B -.-> |Translate| C[Scheduling Database]\\n    C --\x3e B\\n\\n    B -.->|Interpret| D[Supervisor]\\n\\nsubgraph Legend\\n    L1(( )) -.->|Optional| L2(( ))\\n    L3(( )) --\x3e|Mandatory| L4(( ))\\nend\\n```\\n\\n## Demo\\n\\nCheck out the [demo](https://nicholas-goh.com/use-cases/customer-service-automation/ui) before we explore the challenges, technical details, and key insights.\\n\\n<ReactPlayer playing controls url=\'/vid/agentic-rag/customer-service-automation.MOV\' />\\n\\n## Design Choices\\n\\nIn the [previous blog](/blog/etl-automation), prebuilt LangChain agents handled most of the orchestration. However, this no longer applies since no existing prebuilt solution fully fits this use case. A custom approach is needed to orchestrate how the Service and Booking assistants work together.\\n\\nA key consideration is deciding what logic belongs in prompts versus code:\\n\\n- **Booking logic**: Overlapping bookings should be explicitly handled in code rather than inferred through prompts. This involves:\\n  - **SQL triggers** to detect conflicts when a pending booking is inserted.\\n  - **Structured error handling** to prevent hallucinations by ensuring the LLM has clear failure signals. For example:\\n    - *\\"The timeslot overlaps with an existing booking for worker %: conflicting booking from % to %. Next available time is %.\\"* This allows the model to provide accurate responses instead of guessing.\\n\\n- **Assistant selection**: Routing decisions are heuristic at best in code, so an LLM should determine the appropriate assistant. This involves:\\n  - **Supervisor setting execution order**, ensuring assistants act in the correct sequence.\\n  - **Supervisor restructuring queries**, converting user input into precise tasks for each assistant.\\n\\nBy handling failures explicitly at the code level, the system minimizes hallucinations, ensuring that assistants provide accurate and meaningful responses.\\n\\n## Unit Testing\\n\\nUnit testing is crucial for maintaining system reliability, especially in an agentic workflow where:\\n\\n- Small prompt changes can alter agent outputs.\\n- These changes propagate to downstream agents, potentially affecting the entire system.\\n\\nFrom my experience, traditional unit tests don\u2019t always work well in this setup because:\\n\\n- LLM outputs can still vary, even with the same input and temperature set to 0.\\n- Exact string matching is unreliable\u2014tests should pass if expected and actual outputs are semantically equivalent.\\n\\n### Solution: LLM-Based Testing\\n\\nTo address this, an LLM can evaluate test results based on meaning rather than exact wording. This ensures robustness while allowing for natural variations in language.\\n\\n## Tracing: Observability and Monitoring\\n\\n### Understanding the Flow of Requests with Langsmith\\n\\nLangsmith provides a structured way to visualize the flow of a request, making it easier to debug and optimize AI agent interactions. By tracing execution paths, we can pinpoint issues such as:\\n\\n- **Incorrect outputs**: If an agent produces the wrong response, the issue could stem from:\\n  - **Unclear instructions**: The prompt may need refinement to provide better guidance.\\n  - **Misaligned tool descriptions**: The selected tool may not match the query or task.\\n  - **Incorrect input from a previous step**: The agent might be receiving flawed information.\\n  - **Model limitations**: If none of the above apply, the agent may lack the necessary capacity, requiring a model upgrade.\\n- **High latency**: If an agent\'s trace is taking too long to respond, the delay could be caused by:\\n  - **Excessive looping**: By examining the trace of the agent, we can determine if the LLM is repeatedly generating responses. If so, breaking the task into smaller subtasks may improve efficiency.\\n  - **Consistently high latency**: This may indicate network delays or rate limiting.\\n\\nTracing helped me quickly diagnose issues, minimizing debugging time by enabling me to focus directly on areas that needed improvement.\\n\\n### Real-World Examples\\n\\nHere are the sample traces from the demo.\\n\\n- [do u mop kitchen and cabinets](https://smith.langchain.com/public/7e8dd233-a875-48ec-a26c-6d5abab0d81e/r)\\n- [toilet how much and jan 20 9am available?](https://smith.langchain.com/public/b5221550-842c-4814-bbd1-952aeef47497/r)\\n- [jan 20 12pm can](https://smith.langchain.com/public/1b413373-1d00-4985-8c98-1d5f456c967f/r)"},{"id":"etl-automation","metadata":{"permalink":"/blog/etl-automation","source":"@site/blog/2025-02-01-etl-automation/index.mdx","title":"ETL Automation","description":"Introduction","date":"2025-02-01T00:00:00.000Z","tags":[{"inline":true,"label":"agentic-workflow","permalink":"/blog/tags/agentic-workflow"}],"readingTime":7.955,"hasTruncateMarker":true,"authors":[{"name":"Nicholas Goh","title":"AI Full Stack Engineer","url":"https://nicholas-goh.com","page":{"permalink":"/blog/authors/all-nicholas-goh-articles"},"socials":{"linkedin":"https://www.linkedin.com/in/nicholas-goh-19ba1b194/","github":"https://github.com/NicholasGoh"},"imageURL":"https://avatars.githubusercontent.com/u/58037050?s=400&u=cc1cb1686de3cfbf92b95cd8b8bad22291c1a068&v=4","key":"nicholas"}],"frontMatter":{"slug":"etl-automation","title":"ETL Automation","authors":["nicholas"],"tags":["agentic-workflow"]},"unlisted":false,"prevItem":{"title":"Customer Service Automation","permalink":"/blog/customer-service-automation"},"nextItem":{"title":"Agentic RAG","permalink":"/blog/agentic-rag"}},"content":"import ReactPlayer from \'react-player\'\\n\\n## Introduction\\n\\nIn this blog, I explore how automation simplifies problem-solving by testing AI\u2019s ability to break tasks into subproblems. This use case worked with a single agent, but more complex problems require multi-agent orchestration\u2014covered in the [next blog](/blog/customer-service-automation).\\n\\n\x3c!-- truncate --\x3e\\n\\n## AI\u2019s Business Impact: Aligning Technology with Strategy\\n\\nData ingestion is often a bottleneck for businesses dealing with multiple service providers. The challenge isn\'t just handling large volumes of data\u2014it\u2019s managing provider-specific schemas, adapting to schema changes, and maintaining consistency across updates. Manually handling these variations is tedious, error-prone, and difficult to scale.\\n\\nAI-powered automation can help mitigate these challenges by:\\n\\n- Assisting with schema adaptation when providers update their formats.\\n- Reducing operational overhead, allowing teams to focus on higher-value tasks.\\n- Improving efficiency and minimizing downtime caused by schema mismatches.\\n- Supporting more reliable decision-making with structured, up-to-date data ingestion.\\n\\nHowever, AI is not a silver bullet. Risks like hallucinated transformations or misinterpretations of schema changes require robust safeguards. Detailed logging and iterative improvements help detect issues, refine workflows, and adapt the system over time.\\n\\nFor businesses looking to scale, balancing automation with oversight is key. Tracking queries, intermediate steps, and outputs can help to detect errors and patterns. This can help improve the system over time.\\n\\n### The Importance of Orchestration\\n\\nLLMs generate text but cannot execute code. To incorporate execution, they must delegate tasks to external tools and refine responses based on the results. The diagram below illustrates this orchestration. Can this be achieved using prebuilt solutions, or does it require a custom implementation?\\n\\n```mermaid\\ngraph TD;\\n    A[User Query] --\x3e B[LLM]\\n    B -.-> C[Tool]\\n    B -.->|Self Reflection| B\\n    B -.-> D[Finish]\\n    C --\x3e B\\n\\nsubgraph Legend\\n    L1(( )) -.->|Optional| L2(( ))\\n    L3(( )) --\x3e|Mandatory| L4(( ))\\nend\\n```\\n\\n## Demo\\n\\nCheck out the [demo](https://nicholas-goh.com/use-cases/etl-automation/ui) before we explore the challenges, technical details, and key insights.\\n\\n<ReactPlayer playing controls url=\'/vid/agentic-rag/etl-automation.MOV\' />\\n\\n## Navigating Trade-offs in AI System Design\\n\\n### Prebuilt Agent\\n\\nLangchain provides a [prebuilt](https://github.com/langchain-ai/langchain-experimental/blob/libs/experimental/v0.3.4/libs/experimental/langchain_experimental/agents/agent_toolkits/pandas/base.py#L152) CSV Agent. At first glance, it seems to solve the problem of orchestration for me, however, on closer inspection, there are some concerns.\\n\\n#### Pros\\n\\n| Feature                              | Description                                                |\\n|--------------------------------------|------------------------------------------------------------|\\n| **Ease of Use**                      | Works out of the box with minimal setup                    |\\n| **Streaming Events**                 | Supports real-time streaming with intermediate thoughts and actions |\\n| **Observability**                    | Built-in event streaming makes reasoning process transparent |\\n| **Orchestration**                    | Manages tool selection, execution, and self-reflection in a loop until a final response is generated |\\n| **Mental Load**                      | Frees up cognitive effort to focus on high-level problem solving |\\n| **Quick Deployment**                 | Requires minimal configuration, enabling rapid prototyping |\\n\\n:::info[Example Streamed Event]\\n\\n```python\\nAgentAction(\\n  tool=\'python_repl_ast\',\\n  tool_input=\\"df[(df[\'Event Details\'].str.contains(\'09-08-2018\')) & (df[\'Frequency\'] == \'Recurring\')]\\",\\n  log=\'Thought: I need to check if there are any monthly bookings on 9 August 2018 in the dataframe. I will filter the dataframe for entries with the date \\"09-08-2018\\" and a frequency of \\"Recurring\\". Then, I will extract the relevant details for any such bookings.\\\\n\\\\nAction: python_repl_ast\\\\nAction Input: df[(df[\\\\\'Event Details\\\\\'].str.contains(\\\\\'09-08-2018\\\\\')) & (df[\\\\\'Frequency\\\\\'] == \\\\\'Recurring\\\\\')] \'\\n  observation=\'\'\'\\n    Customer Invoice No.,Event Details,Link Event,Customer Name,Provider Name,Frequency,Hourly Rate,Duration,Amount Gross,Amendments,Gross Difference,Unnamed: 11\\n    1b1c9f58-bd91-4289-929f-948e718e2473,04-08-2018 09:30,link,Alice Ng,SparkleClean Services,Cancellation,22.5,2.5,0.0,Yes,-66.25,\\n    ...\\n    \'\'\'\\n)\\n```\\n\\nAs seen above, prebuilt agent will:\\n\\n- handle [the orchestration](#the-importance-of-orchestration)\\n- streamed events that can be transmitted to the frontend using a preferred server-client communication method (e.g., WebSockets, Server-Sent Events)\\n  - this enables real-time rendering of the agent\'s thought process, enhancing transparency and user experience.\\n\\n:::\\n\\n#### Cons\\n\\n| Feature                              | Description                                                |\\n|--------------------------------------|------------------------------------------------------------|\\n| **Limited Flexibility**               | Predefined agents exist (e.g., Pandas Dataframe Agent), but lacks support for problems that requires specialized agents |\\n| **Restricted Orchestration Between Agents** | Difficult to implement complex multi-agent workflows when the problem demands specialized coordination |\\n\\nFor this blog, the Pandas DataFrame Agent is well-suited for the ETL use case, making LangChain\u2019s prebuilt solution a practical choice. The problem scope does not require multi-agent coordination, so the limitations in orchestration are not a concern here. However, I will still explore an alternative that offers greater flexibility in designing custom agent interactions: LangGraph.\\n\\n### Alternative: Langgraph\\n\\nLanggraph presents a compelling alternative when the use case demands greater flexibility in orchestrating multiple agents. Unlike Langchain\u2019s predefined agents, Langgraph allows for customizable workflows, enabling multi-agent collaboration, conditional logic, and more complex decision-making.\\n\\n#### **Pros**\\n\\n| Feature                              | Description                                                |\\n|--------------------------------------|------------------------------------------------------------|\\n| **Flexible Orchestration**           | Allows for complex agent workflows, including multi-agent interactions, conditional branching, and asynchronous execution. |\\n| **Fine-Grained Control**             | Developers can define precise execution logic, ensuring that agents interact optimally based on the use case\u2019s needs. |\\n| **Extensibility**                    | Provides a modular foundation to scale and integrate with other AI components as requirements evolve. |\\n\\n#### **Cons**\\n\\n| Feature                              | Description                                                |\\n|--------------------------------------|------------------------------------------------------------|\\n| **Increased Complexity**             | Greater customization comes with a steeper learning curve and higher development effort compared to Langchain\u2019s prebuilt agents. |\\n| **Manual Implementation Required**   | Orchestration has to be manually implemented as opposed to the prebuilt one in Langchain. |\\n\\nWhile Langchain\u2019s predefined agents are sufficient for this ETL use case, exploring Langgraph lays the groundwork for the [next blog](/blog/customer-service-automation), where the problem scope justifies the need for a more advanced, multi-agent orchestration approach. Given this, I ultimately chose to implement Langgraph for this blog.\\n\\n## Scaling AI Systems: Architectural and Operational Insights\\n\\n### Scaling Considerations for a Small User Base\\n\\nThe initial goal is to support tens of users effectively while ensuring a balance between performance and cost-efficiency. Right out of the box, the OpenAI API and FastAPI as the backend handle concurrency efficiently, reducing the need for additional scaling efforts in the early stages.\\n\\n### Exploring Groq for Fast Agentic Workflows\\n\\nGroq presents an alternative cloud provider for LLMs, particularly excelling in agentic workflows requiring rapid responses. Key observations:\\n\\n- It delivers significantly faster inference times, enhancing user experience.\\n- From my experience, it tends to be more talkative but less effective at solving tasks compared to GPT-4O-Mini.\\n- The cost is approximately six times higher than mainstream alternatives.\\n- Given the above trade-offs, I did not invest heavily in prompt engineering, as the core focus of this blog is not on achieving low latency.\\n\\nChoosing the right LLM cloud provider with my current goal in mind is essential\u2014treating this as a stepping stone rather than an endless pursuit of the \\"best\\" solution. There will always be \\"better\\" approaches for different use cases, but without a clear stopping point, I risk constantly iterating without making real progress.\\n\\n## Failure Analysis: Debugging and Mitigating AI Pitfalls\\n\\n### The Interplay Between Prompts and Models\\n\\nGiven the scaling experiment [above](#scaling-considerations-for-a-small-user-base), I noticed that prompt-model tagging will be necessary should I continue on the path of different models in production. As each model is trained differently, prompts are model-specific and should be tagged to each model for best results.\\n\\n### The Importance of a Hallucination Detection Module\\n\\n```mermaid\\ngraph TD;\\n    A[User Query] --\x3e B[LLM]\\n    B -.-> C[Hallucination Reduction Module]\\n    C -.-> D[Tool]\\n    D --\x3e B\\n    C -.->|Self Reflection| B\\n    B -.-> E[Finish]\\n\\nsubgraph Legend\\n    L1(( )) -.->|Optional| L2(( ))\\n    L3(( )) --\x3e|Mandatory| L4(( ))\\nend\\n```\\n\\nIn hindsight, integrating a hallucination detection module is crucial, even if it does not entirely prevent incorrect outputs. It provides an additional layer of reasoning and debugging, helping to:\\n\\n- Detect inconsistencies in model-generated responses before Python pandas code is executed\\n- Reduces the risk of propagating erroneous outputs.\\n\\nHowever, implementing such a module increases system complexity. Given this, I hope to cover better orchestration strategies in a separate blog.\\n\\n## Security Risks and Best Practices in AI Systems\\n\\nUsing a prebuilt pandas DataFrame agent introduces security risks by exposing system Python execution to anyone accessing the system. In a production environment, this can have serious implications:\\n\\n- **Containerized Deployment on AWS**\\n  - The production environment runs in AWS-managed containers.\\n  - Containers are ephemeral\u2014if the environment is corrupted, they can be easily destroyed and redeployed.\\n  - They contain nothing of value other than the API key (discussed in the next section).\\n  - My personal desktop remains unaffected by these risks.\\n\\n### API Key Exposure and Mitigation Strategies\\n\\n- **Risk of OpenAI API Key Exposure**\\n  - The API key must be accessible on the production server to interact with GPT-4O-Mini.\\n  - While restricting API key exposure at the prompt level (e.g., preventing it from being output) may seem like a solution, it can be bypassed via jailbreak techniques.\\n  - To mitigate this, I have enforced security at the code level, ensuring the API key is never exposed in logs, responses, or accessible environments.\\n    - Additionally, I have implemented usage limits at the API provider level to cap monthly expenses, serving as a fail-safe in case of unexpected leaks or abuse.\\n\\n- **Potential and Unknown Attack Vectors**\\n  - Despite implemented safeguards, I am aware of specific ways my API key could still be leaked.\\n  - Additionally, unknown vulnerabilities may exist, which need continuous assessment and mitigation.\\n\\n### Long-Term Security Considerations\\n\\nIf this system is scaled further, securing the API key and the overall infrastructure must be a top priority. A more comprehensive approach\u2014including environment isolation, access controls, and strict request validation\u2014should be taken to minimize security risks.\\n\\n## Lessons Learned from AI Deployments\\n\\nAgentic workflows are just tools, not solutions\u2014they require a clear use case or domain-specific challenge to be effective. Not every problem warrants an agentic approach; the complexity must justify the need for automation. Scalability and efficiency should be considered from the start, ensuring workflows remain adaptable through iterative improvements."},{"id":"agentic-rag","metadata":{"permalink":"/blog/agentic-rag","source":"@site/blog/2024-11-07-agentic-rag/index.mdx","title":"Agentic RAG","description":"Introduction","date":"2024-11-07T00:00:00.000Z","tags":[{"inline":true,"label":"agentic-workflow","permalink":"/blog/tags/agentic-workflow"},{"inline":true,"label":"rag","permalink":"/blog/tags/rag"}],"readingTime":15.925,"hasTruncateMarker":true,"authors":[{"name":"Nicholas Goh","title":"AI Full Stack Engineer","url":"https://nicholas-goh.com","page":{"permalink":"/blog/authors/all-nicholas-goh-articles"},"socials":{"linkedin":"https://www.linkedin.com/in/nicholas-goh-19ba1b194/","github":"https://github.com/NicholasGoh"},"imageURL":"https://avatars.githubusercontent.com/u/58037050?s=400&u=cc1cb1686de3cfbf92b95cd8b8bad22291c1a068&v=4","key":"nicholas"}],"frontMatter":{"slug":"agentic-rag","title":"Agentic RAG","authors":["nicholas"],"tags":["agentic-workflow","rag"]},"unlisted":false,"prevItem":{"title":"ETL Automation","permalink":"/blog/etl-automation"}},"content":"import ReactPlayer from \'react-player\'\\nimport ArchitectureDiagram from \'./architecture-diagram.svg\';\\n\\n## Introduction\\n\\nIt has been a while since I last shared my thoughts on designing and building an Agentic RAG system in my previous [Medium Blog](https://medium.com/@gohn0004/agentic-rag-36d38b20fb1f). In this post, I aim to first discuss the inspiration behind building the system and then delve into the challenges I encountered, along with potential future hurdles.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Inspiration\\n\\n### The Role of RAG\\n\\nConsider the following question:\\n\\n> **Question:** What is a famous Taylor Swift song?\\n\\n:::info[common knowledge]\\n\\nCruel Summer\\n\\n:::\\n\\nA domain expert is not needed for the above question as the average person can answer this.\\n\\nNow, consider the next question:\\n\\n> **Question:** What are the symptoms of bipolar?\\n\\n:::info[domain expert]\\n\\n<details>\\n\\n  <summary>Expand Excerpt</summary>\\n\\n**Diagnostic Criteria for Bipolar Disorder** *(Excerpt retrieved from a [clinical reference](https://repository.poltekkes-kaltim.ac.id/657/1/Diagnostic%20and%20statistical%20manual%20of%20mental%20disorders%20_%20DSM-5%20(%20PDFDrive.com%20).pdf))*\\n\\n> **7**. Decreased need for sleep (feeling rested despite sleeping less than usual; to be contrasted with insomnia)\\n\\n  > **A**. Mixed symptoms are observable by others and represent a change from the person\u2019s usual behavior.\\n\\n  > **B**. For individuals whose symptoms meet full criteria for either mania or hypomania, the diagnosis should be bipolar I or bipolar II disorder.\\n\\n  > **C**. The mixed symptoms are not attributable to the physiological effects of a substance (e.g., a drug of abuse, a medication or other treatment).\\n\\n> **Note**: Mixed features associated with a major depressive episode have been found to be a significant risk factor for the development of bipolar I or bipolar II disorder. As a result, it is clinically useful to note the presence of this specifier for treatment planning and monitoring of response to treatment.\\n\\n</details>\\n\\nSymptoms of bipolar disorder include episodes of mania, which may involve rapid speech, racing thoughts, distractibility, and decreased need for sleep. Additionally, individuals may experience depressive episodes characterized by feelings of sadness, hopelessness, and loss of interest in activities. Mixed features can also occur, where symptoms of both mania and depression are present simultaneously.\\n\\n:::\\n\\nThe *average person* would not know the answer to the above question. Instead, this question is best answered by a **domain expert**.\\n\\nSimilarly, RAG is needed in some queries but not in others. However, should RAG be used in all queries?\\n\\n### Is RAG the Right Solution for Everything?\\n\\nCan RAG\'s retrieved contexts corrupt LLM\'s knowledge?\\n\\n> **Question**: What are some effective strategies to improve sleep quality?\\n\\n:::info[domain expert]\\n\\n<details>\\n\\n  <summary>Expand Excerpt</summary>\\n\\n**Diagnostic Criteria for Bipolar Disorder** *(Excerpt retrieved from a [clinical reference](https://repository.poltekkes-kaltim.ac.id/657/1/Diagnostic%20and%20statistical%20manual%20of%20mental%20disorders%20_%20DSM-5%20(%20PDFDrive.com%20).pdf))*\\n\\n> **7**. Decreased need for sleep (feeling rested despite sleeping less than usual; to be contrasted with insomnia)\\n\\n  > **A**. Mixed symptoms are observable by others and represent a change from the person\u2019s usual behavior.\\n\\n  > **B**. For individuals whose symptoms meet full criteria for either mania or hypomania, the diagnosis should be bipolar I or bipolar II disorder.\\n\\n  > **C**. The mixed symptoms are not attributable to the physiological effects of a substance (e.g., a drug of abuse, a medication or other treatment).\\n\\n> **Note**: Mixed features associated with a major depressive episode have been found to be a significant risk factor for the development of bipolar I or bipolar II disorder. As a result, it is clinically useful to note the presence of this specifier for treatment planning and monitoring of response to treatment.\\n\\n</details>\\n\\nA decreased need for sleep is not necessarily problematic, as some individuals feel rested despite sleeping less than usual. However, if sleep disturbances are accompanied by changes in mood or energy levels, it could be indicative of bipolar disorder. In such cases, it may be clinically useful to monitor symptoms and consider treatment options.\\n\\n:::\\n\\nInstead of giving tips on sleeping, such as *reducing screen time before bed* or *improving pillow quality*, the LLM\'s completion can be **corrupted** to a *bipolar disorder bias*.\\n\\nHow can I dynamically route questions between a RAG-powered domain expert and a vanilla LLM for general knowledge?\\n\\n### The Importance of Orchestration\\n\\n```mermaid\\ngraph TD\\n    A[Query] --\x3e|Retrieval System| B[Context]\\n    B --\x3e C{Agent Checks Relevance}\\n    A --\x3e C\\n    C --\x3e|Relevant| D[LLM + Context]\\n    C --\x3e|Not Relevant| E[LLM]\\n    D --\x3e F[Answer]\\n    E --\x3e F[Answer]\\n```\\n\\n> **Relevance Prompt:** Given the following context and a chat history with the latest user question, decide if the context is relevant or not. Do not guess. If you do not know, say no. Reply only yes or no. \\\\{context\\\\} \\\\{history\\\\} \\\\{query\\\\}\\n\\n:::tip\\n\\nThis is a straightforward routing problem, so a simple prompt will do.\\n\\nFor a more complex case that requires advanced prompts and workflows, check out [this blog](/blog/etl-automation).\\n\\n:::\\n\\nWhile multiple approaches exist, this application aims to minimize complexity while maintaining effectiveness, aligning with Occam\u2019s Razor. The future sections will discuss potential optimizations, trade-offs, and metrics for evaluating success.\\n\\n## Demo\\n\\nFeel free to check out the demo [here](https://nicholas-goh.com/ui) before I dive into the challenges, technical details, and implementations!\\n\\n<ReactPlayer playing controls url=\'/vid/agentic-rag/agentic-rag.MOV\' />\\n\\n## Challenges Encountered\\n\\n### Production Challenges in an Agentic RAG System\\n\\n:::warning\\n\\nAgents = LLM + Tool?\\n\\nRAG = LLM + Vectorstore?\\n\\n:::\\n\\nAgents and RAG are easy to grasp conceptually but offer eye-opening insights when implemented in production.\\n\\nDespite passing tests for correctly orchestrating RAG, then correctly retrieving relevant contexts in development, I faced a few issues in production.\\n\\nThe agentic workflow for determining if RAG is needed occasionally made incorrect choices for certain user queries. Some edge cases were overlooked during development, either due to human error or the inherent difficulty of anticipating all scenarios.\\n\\nAdditionally, some retrieved RAG contexts were not helpful in answering queries exposed mismatches\u2014chunks were sometimes too small for broad queries and too large for highly specific ones.\\n\\nPerhaps these can be mitigated after further examining the following section.\\n\\n## Challenges in Refining a RAG System\\n\\n### Mitigating Hallucinations\\n\\nThis flowchart outlines a possible Hallucination Reduction Module, which explores rejecting low-confidence outputs and using prompt engineering to assess response accuracy and relevance.\\n\\n```mermaid\\ngraph TD;\\n    A[LLM + Context] --\x3e B\\n    B[Hallucination Reduction Module] --\x3e C[Reject Low Confidence Scores]\\n    B --\x3e D[Prompt Engineering]\\n\\n    D --\x3e E{Does this answer query given context?}\\n    E -- No --\x3e F[LLM]\\n    E -- Yes --\x3e G{Does answer with context answer query better than without context?}\\n    G -- No --\x3e F\\n    G -- Yes --\x3e H[Accept Response]\\n```\\n\\n### Breaking Down RAG Component Challenges\\n\\nRAG comprises of many components, listed as subsections in this section.\\n\\nEach of these components can be optimized, with improvements\u2014and unfortunately, _errors_\u2014propagating to subsequent stages.\\n\\nThis raises a crucial question, answered in the next section: **How can I measure and evaluate RAG performance?**\\n\\n#### Document Type Ingestion\\n\\n| **File Type** | **Challenges** | **Required Handling** |\\n|-------------|--------------|------------------|\\n| **PDF** | Varying structures (scanned, OCR, embedded text) | Specialized PDF parsers (e.g., PyMuPDF, pdfplumber, Tesseract for OCR) |\\n| **HTML** | Presence of scripts, ads, and formatting inconsistencies | HTML parsing and cleaning (e.g., BeautifulSoup, trafilatura) |\\n| **Word Docs (DOCX)** | Embedded images, tables, and complex formatting | DOCX-specific parsers (e.g., python-docx) |\\n| **Plain Text** | Lack of structure, possible encoding issues | Minimal processing but may require cleaning and normalization |\\n\\n#### Chunking Strategy\\n\\n| **Chunk Size**  | **Pros** | **Cons** | **Use Case** |\\n|----------------|---------|---------|-------------|\\n| **Large Chunks** | Retains broader context for answering comprehensive or multi-hop queries | May introduce irrelevant information, increasing LLM confusion | *\\"What are the legal obligations under Section 12?\\"* (May require referencing multiple sections) |\\n| **Small Chunks** | Provides precise and relevant information for focused queries | Lacks surrounding context, potentially missing key details | *\\"What is the refund policy for digital products?\\"* (Specific, direct retrieval) |\\n\\n#### Embedding and Response Model\\n\\n| **Model**   | **Pros**                                      | **Cons**                                       | **Best For**                |\\n|----------------------|----------------------------------------------|----------------------------------------------|----------------------------|\\n| **Domain-Specific**  | Captures nuances in fields like law & medicine | Costly to develop and maintain                | Specialized applications   |\\n| **Generic**         | Easy to update and maintain                    | May underperform in niche domains             | Broad, multi-domain tasks  |\\n\\n#### Retriever Strategy\\n\\n| **Retriever Strategy**  | **Pros** | **Cons** | **Use Case** |\\n|------------------------|---------|---------|-------------|\\n| **Keyword Search (BM25, TF-IDF)** | Fast and precise for exact terms | Misses semantic matches | Legal or regulatory text search |\\n| **Dense Vector Search** (dot product, cosine similarly, etc...) | Captures semantic meaning | May retrieve irrelevant results | General RAG with natural language queries |\\n| **Re-Ranker** | Improves relevance of retrieved results | Slower and more compute-heavy | High-precision search (legal, medical) |\\n\\n### RAG Evaluation\\n\\nShould RAG be evaluated end to end naively with accuracy as the metric? If the [retrieved context is wrong but the response generated from this context is correct](#is-rag-the-right-solution-for-everything), should the metric reflect this or simply label the answer as wrong.\\n\\nHow can context and response generation be evaluated separately?\\n\\n[Ragas](https://docs.ragas.io/en/latest/concepts/metrics/available_metrics/#retrieval-augmented-generation) provides a list of metrics.\\n\\n## Medium Blog\\n\\nAs mentioned, this post builds upon my previous Medium blog, which you can find [here](https://medium.com/@gohn0004/agentic-rag-36d38b20fb1f) or read below for your convenience.\\n\\n<ArchitectureDiagram />\\n\\n### Cloud Deployment\\n\\n#### Deploying with BentoML\\n\\nAfter reading about deploying Agents with BentoML\u2019s FAAS, I started my own experiment with a simple function utilizing OpenAI\u2019s GPT 4. BentoML\u2019s Infrastructure as Code (IaC) allowed me to set up compute resources, scaling, and containerization almost effortlessly, quickly providing me with callable API endpoints. While effective, the daily cost of approximately SGD 1.5, for a personal project, led me to explore more budget-friendly options.\\n\\n#### Transitioning to AWS\\n\\nAWS presented a more affordable path, but as a newcomer to the platform, I had to make some System Architectue choices. Do I use Lambda as my API Endpoints and Amplify to deploy my UI or should I deploy everything on an EC2 Instance? Here\u2019s what I considered.\\n\\n##### Option 1\u2014Lambda + Amplify\\n\\nThis approach required a microservice architecture where the UI and API were loosely coupled. Testing both cloud-only components together would add time to my development process, so I opted to avoid the added complexity of managing a distributed system at this stage.\\n\\n##### Option 2\u2014EC2\\n\\nWith Docker Compose and EC2, I could easily develop, test, and debug both locally and on the server. This unified approach reduced setup complexities and kept my infrastructure manageable.\\n\\n### Backend: Framework and Feature Selection\\n\\n#### RAG Framework\\n\\nThere are many frameworks to do RAG: Llamaindex, Langchain, Korvus to name a few. Llamaindex is a niche RAG framework while Langchain is a larger toolkit capable of many extra bells and whistles that I do not require for this project.\\n\\n##### Event Streaming\\n\\nLlamaindex supports streaming responses, which is a must have. This allows streaming the completions from API to UI in real time as opposed to waiting for everything to be generated before sending it over. But what if I want intermediate steps taken by Llamaindex, for example, seeing the final prompt sent to OpenAI or the relevant contexts retrieved before the generation in RAG? Langchain makes this easier with Event Streaming. Events are easily accessed with:\\n\\n```text\\non_retriever_stream\\non_chat_model_stream\\non_prompt_stream\\n```\\n\\n##### Agent Orchestration\\n\\nBoth Llamaindex and Langchain have agent capabilities but dictating the flow between (if any) LLM, custom tool and other LLMs is hacky at best. What if I want a hierarchy? A supervisor agent delegating tasks to worker agents to execute. What if I want this agent to always call a custom tool? Langgraph immediately comes to mind as Agent Orchestration is exposed as a graph for a lot of control. Again, integration with Langchain is made easier with event stream as compared to Llamindex.\\n\\n##### Langchain vs Korvus\\n\\nKorvus allows RAG to be done at the SQL level via PostgresML. This greatly reduces the codebase I have to develop and maintain; I don\u2019t have to construct Langchain chunkers, vectorizers and retrievers, and can simply specify a configuration for Korvus to manage the chunking and vectorizing stages in addition to the retrieval stage. Furthermore, PostgresML supports cloud and self hosted deployments. However, due to event streaming and the fact that I haven\u2019t caught up with newer versions of Langchain in awhile, I decide to catchup and use Langchain.\\n\\n#### Agentic RAG\\n\\nFor this project, I decided to fix ingestion to just one document. DSM 5 is a large 992 page document describing many disorders and the diagnostic criteria among other things. How can I ascertain if the user query should be answered with contexts retrieved from this document? Do I simply check if the query is related to any form of disorder or diagnostic criteria? Can the contents of 992 pages be condensed into the previous sentence?\\n\\nInstead, I decided to retrieve relevant contexts for any query. From here, I delegate the decision to an agent: are these contexts relevant to the query, given the current chat history? As this agent orchestration is minimal I was able to keep things simple with Langchain\u2019s chaining instead of using Langgraph\u2019s more powerful orchestration at the cost of complexity. As detailed in the diagram, if the contexts are relevant, they are used in the generation part of RAG. If not, a normal LLM call is made with the system prompt, user query and chat history if any instead. This call would then be identical to endpoint:\\n\\n```text\\n/completions\\n```\\n\\n#### Database\\n\\nI needed to store metadata and vectors.\\n\\n##### Metadata\\n\\nI wanted DB transactions to be ACID so I chose the well known Postgres to help enforce this.\\n\\n##### Vectorstore\\n\\nAt the time, I wasn\u2019t sure how big a document I would settle with, nor the number of embeddings i would end up with. Milvus caught my eye as it can cater to at least a few million vectors and seemed to be the go to vectorstore. As it turned out, this didn\u2019t matter as I ended up with a little under 5k vectors.\\n\\n##### Cross DB Consistency\\n\\nHowever, the larger problem was ensuring vectors were inserted when metadata was inserted. Suppose a vector insertion into Milvus fails, I would need to implement checks and rollbacks to rollback metadata insertion into Postgres increasing my development time. As such, I decided to have all my data together in PGVector where easier rollbacks can be done.\\n\\n#### Scalability\\n\\nThis is a personal project that I probably won\u2019t spend time scaling. However, suppose I did, the first thing to fail at scale would probably be my API. LLM completions are streamed to UI with FastAPI\u2019s asynchronous functions. This can potentially block the whole API\u2019s event loop due Python and its GIL. Increasing Uvicorn workers could help solve this issue.\\n\\n#### Ingestion\\n\\nTo keep EC2 costs low, I chose the smallest CPU. This meant I had to carefully design how to handle loading, chunking and vectorizing pages to reduce RAM usage. After experimentation, I found I could smoothly preprocess the PDF 50 pages at a time. However, this means I lose a potentially relevant chunk of context, perhaps the last line of page 50 and the beginning line of page 51. To combat this, I process the PDF 50 pages at a time, with a rolling window of 49. This ensures the chunk between page 50 and 51 is not lost, with the small tradeoff of very similar chunks on page 50 as it is chunked twice.\\n\\n#### Terraform IaC\\n\\nI didn\u2019t want to manually click the console to provision resources as I would forget what to click, but more importantly, running code is faster and more reproducible than clicking to provision resources. I configured Terraform configs to:\\n\\n- provision EC2, pinning ubuntu image\\n- ingress egress security policies to and fro EC2\\n- elastic IP for static IP address to point my domain to\\n- provision ECR\\n- image deletion policies for old images on ECR to save costs\\n- access policies to ECR\\n- build, tag my deployment containers then push them to ECR\\n- With the above, I can easily destroy all resources should I chose to, where manually doing so might result in me forgetting to destroy something, incurring unwanted costs.\\n\\n### UI\\n\\nI didn\u2019t want to spend time developing my UI from scratch so I found this open source UI and forked it. There were still 2 major things I had to do: Authentication and API integration.\\n\\n#### Clerk Authentication\\n\\nI found Clerk to be an easy way to add authentication to my UI. It greatly removed parts of my development time as I didn\u2019t need to implement any login/logout components, nor worry about implementing authentication from scratch. With the user id provided by Clerk, I am able to store user specific queries and chat history for multi user experience.\\n\\n#### API Integration\\n\\nI stopped UI from handling OpenAI API calls as I wanted my API to handle it. Most AI frameworks, mature or cutting edge, tend to be written in Python so further work is made easier by porting calls from UI to API. I wanted UI to fetch data from API as API is connected to my DB, instead of storing and retrieving data on the client side with vanilla localstorage in typescript. Furthermore, I wanted UI to accept Server Sent Events (SSE) via EventSource instead of decoding a POST to API with TextDecoder. I decided on SSE over Websockets (WS) as I only needed one way communication and SSE implementation required less boilerplate in API, for better maintainability. In addition, I removed some functionalities to make things simpler, such as selection of current and previous conversations and exposing the choosing of prompts.\\n\\n### Possible Future Work\\n\\n#### RAG Improvements\\n\\nEach component of RAG can be improved. Better embedding model, more chunking with the tradeoff of too similar/redundant chunks, better LLM model. In addition, I did not incorporate a reranker to prioritize relevant contexts retrieved before generation.\\n\\n#### On Premise\\n\\nI understand that RAG might be required to run offline for sensitive documents. I have no plans to carry this out for this personal project, but I am aware of the steps to be taken. I can swap out the embedding and completion models from text-embedding-3-small and gpt-4o-mini to respective local models such as hkunlp/instructor-large and llama-3\u201370b-instruct. Before doing so, I would need to check if the literature supports the efficacy of these models. Important questions would be what is the task to be solved, so the metric to validate efficacy can be chosen.\\n\\n#### Terraform\\n\\nI have not configured terraform to provision status checks and alarms, though I have configured them manually to alert me when my application is down. Furthermore, I still have much to learn such as creation and management of accounts and access policies for the respective accounts.\\n\\n#### Refactor UI\\n\\nCurrently, most of the logic is in a single large file. It is time to pay off technical debt and refactor into bite-sized components for easier future development and maintenance. Instead of passing props through many layers of nested components, I can consider using a state management solution like Zustand. However, I will need to weigh the tradeoff of having some boilerplate code for the state management.\\n\\n### Conclusion\\n\\nWorking on this project was both engaging and insightful. It allowed me to leverage my existing knowledge, while also uncovering new concepts and filling in knowledge gaps I hadn\u2019t anticipated."}]}}')}}]);